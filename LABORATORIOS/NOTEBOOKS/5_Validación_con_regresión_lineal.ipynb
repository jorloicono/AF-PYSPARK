{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 577
        },
        "id": "_c3XwoPTyXgC",
        "outputId": "c68f1563-d3b1-4a1a-a59d-248aadb97141"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyspark\n",
            "  Downloading pyspark-3.3.2.tar.gz (281.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m281.4/281.4 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting py4j==0.10.9.5\n",
            "  Downloading py4j-0.10.9.5-py2.py3-none-any.whl (199 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.7/199.7 KB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.3.2-py2.py3-none-any.whl size=281824025 sha256=f6e35bb6bf9fac4bf9c0fdf098f01708f2a401f80b7221fdbe4eebb4c07658c9\n",
            "  Stored in directory: /root/.cache/pip/wheels/6c/e3/9b/0525ce8a69478916513509d43693511463c6468db0de237c86\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9.5 pyspark-3.3.2\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting findspark\n",
            "  Downloading findspark-2.0.1-py2.py3-none-any.whl (4.4 kB)\n",
            "Installing collected packages: findspark\n",
            "Successfully installed findspark-2.0.1\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7efd4efbc6a0>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://6383822dac76:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.3.2</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>pyspark-shell</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "!pip install pyspark\n",
        "!pip install findspark\n",
        "\n",
        "# Import SparkSession\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "# Create a Spark Session\n",
        "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()\n",
        "\n",
        "# Check Spark Session Information\n",
        "spark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.evaluation import RegressionEvaluator\n",
        "from pyspark.ml.regression import LinearRegression\n",
        "from pyspark.ml.tuning import ParamGridBuilder, TrainValidationSplit\n",
        "\n",
        "# Prepare training and test data.\n",
        "data = spark.read.format(\"libsvm\")\\\n",
        "    .load(\"/content/sample_linear_regression_data.txt\")\n",
        "train, test = data.randomSplit([0.9, 0.1], seed=12345)\n",
        "\n",
        "lr = LinearRegression(maxIter=10)\n",
        "\n",
        "# We use a ParamGridBuilder to construct a grid of parameters to search over.\n",
        "# TrainValidationSplit will try all combinations of values and determine best model using\n",
        "# the evaluator.\n",
        "paramGrid = ParamGridBuilder()\\\n",
        "    .addGrid(lr.regParam, [0.1, 0.01]) \\\n",
        "    .addGrid(lr.fitIntercept, [False, True])\\\n",
        "    .addGrid(lr.elasticNetParam, [0.0, 0.5, 1.0])\\\n",
        "    .build()\n",
        "\n",
        "# In this case the estimator is simply the linear regression.\n",
        "# A TrainValidationSplit requires an Estimator, a set of Estimator ParamMaps, and an Evaluator.\n",
        "tvs = TrainValidationSplit(estimator=lr,\n",
        "                           estimatorParamMaps=paramGrid,\n",
        "                           evaluator=RegressionEvaluator(),\n",
        "                           # 80% of the data will be used for training, 20% for validation.\n",
        "                           trainRatio=0.8)\n",
        "\n",
        "# Run TrainValidationSplit, and choose the best set of parameters.\n",
        "model = tvs.fit(train)\n",
        "\n",
        "# Make predictions on test data. model is the model with combination of parameters\n",
        "# that performed best.\n",
        "model.transform(test)\\\n",
        "    .select(\"features\", \"label\", \"prediction\")\\\n",
        "    .show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8jkWxw-_yZfr",
        "outputId": "a23bd387-9186-4222-bc0a-fb817dbea8d5"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+--------------------+--------------------+\n",
            "|            features|               label|          prediction|\n",
            "+--------------------+--------------------+--------------------+\n",
            "|(10,[0,1,2,3,4,5,...| -17.026492264209548| -1.6552077975758144|\n",
            "|(10,[0,1,2,3,4,5,...|  -16.71909683360509|-0.06173284202439916|\n",
            "|(10,[0,1,2,3,4,5,...| -15.375857723312297|  0.6949088125477225|\n",
            "|(10,[0,1,2,3,4,5,...| -13.772441561702871|  3.9104769954029184|\n",
            "|(10,[0,1,2,3,4,5,...| -13.039928064104615|  0.3433433960676067|\n",
            "|(10,[0,1,2,3,4,5,...|   -9.42898793151394| -4.0115565332806575|\n",
            "|(10,[0,1,2,3,4,5,...|    -9.2679651250406|-0.05502173816316347|\n",
            "|(10,[0,1,2,3,4,5,...|  -9.173693798406978|-0.28813191486076367|\n",
            "|(10,[0,1,2,3,4,5,...| -7.1500991588127265|   3.418347141475304|\n",
            "|(10,[0,1,2,3,4,5,...|  -6.930603551528371|0.030343256659171147|\n",
            "|(10,[0,1,2,3,4,5,...|  -6.456944198081549|-0.45788602578523113|\n",
            "|(10,[0,1,2,3,4,5,...| -3.2843694575334834| -0.7807226371771443|\n",
            "|(10,[0,1,2,3,4,5,...|   -1.99891354174786|   0.929197026036511|\n",
            "|(10,[0,1,2,3,4,5,...| -0.4683784136986876|   0.500707021593821|\n",
            "|(10,[0,1,2,3,4,5,...|-0.44652227528840105| 0.09299575091220402|\n",
            "|(10,[0,1,2,3,4,5,...| 0.10157453780074743| -0.9347679854895306|\n",
            "|(10,[0,1,2,3,4,5,...|  0.2105613019270259|  1.4611389615090573|\n",
            "|(10,[0,1,2,3,4,5,...|  2.1214592666251364|  0.3567627282595647|\n",
            "|(10,[0,1,2,3,4,5,...|  2.8497179990245116|  1.5555843666327929|\n",
            "|(10,[0,1,2,3,4,5,...|   3.980473021620311|  2.9607153280327885|\n",
            "+--------------------+--------------------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    }
  ]
}