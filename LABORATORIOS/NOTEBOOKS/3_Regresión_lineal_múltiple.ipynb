{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspark\n",
        "!pip install findspark\n",
        "\n",
        "# Import SparkSession\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "# Create a Spark Session\n",
        "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()\n",
        "\n",
        "# Check Spark Session Information\n",
        "spark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 577
        },
        "id": "DwtA13e5_gxE",
        "outputId": "8bac869b-0ab2-43fa-f56a-8517fe906655"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyspark\n",
            "  Downloading pyspark-3.3.2.tar.gz (281.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m281.4/281.4 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting py4j==0.10.9.5\n",
            "  Downloading py4j-0.10.9.5-py2.py3-none-any.whl (199 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.7/199.7 KB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.3.2-py2.py3-none-any.whl size=281824025 sha256=4608ac91bd4b5fb56ff6458ff818ea64491b2cc57b1db9167140f39017b574fd\n",
            "  Stored in directory: /root/.cache/pip/wheels/6c/e3/9b/0525ce8a69478916513509d43693511463c6468db0de237c86\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9.5 pyspark-3.3.2\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting findspark\n",
            "  Downloading findspark-2.0.1-py2.py3-none-any.whl (4.4 kB)\n",
            "Installing collected packages: findspark\n",
            "Successfully installed findspark-2.0.1\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7f4938bc26d0>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://f6ccc66ccb8c:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.3.2</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>pyspark-shell</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "vlOZI5PM_fvE"
      },
      "outputs": [],
      "source": [
        "# (1) Import the required Python dependencies\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import findspark\n",
        "findspark.init()\n",
        "from pyspark import SparkContext, SparkConf\n",
        "from pyspark.sql import SQLContext\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.ml.regression import LinearRegression\n",
        "from pyspark.ml.evaluation import RegressionEvaluator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2zrdHhL3_fvH",
        "outputId": "8ebd3299-99a2-4fad-a9dd-0982abfa6379"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/pyspark/sql/context.py:112: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# (2) Instantiate a Spark Context\n",
        "sqlContext = SQLContext(spark)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iVVWL-0Z_fvJ",
        "outputId": "dbe25f0c-27ee-4ff3-fd02-1559b8e6f79a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-------------------+------+---+----+-------+-------+----------+----------+--------+--------+--------+---------+------+----------+----+\n",
            "|instant|             dteday|season| yr|mnth|holiday|weekday|workingday|weathersit|    temp|   atemp|     hum|windspeed|casual|registered| cnt|\n",
            "+-------+-------------------+------+---+----+-------+-------+----------+----------+--------+--------+--------+---------+------+----------+----+\n",
            "|      1|2011-01-01 00:00:00|     1|  0|   1|      0|      6|         0|         2|0.344167|0.363625|0.805833| 0.160446|   331|       654| 985|\n",
            "|      2|2011-01-02 00:00:00|     1|  0|   1|      0|      0|         0|         2|0.363478|0.353739|0.696087| 0.248539|   131|       670| 801|\n",
            "|      3|2011-01-03 00:00:00|     1|  0|   1|      0|      1|         1|         1|0.196364|0.189405|0.437273| 0.248309|   120|      1229|1349|\n",
            "|      4|2011-01-04 00:00:00|     1|  0|   1|      0|      2|         1|         1|     0.2|0.212122|0.590435| 0.160296|   108|      1454|1562|\n",
            "|      5|2011-01-05 00:00:00|     1|  0|   1|      0|      3|         1|         1|0.226957| 0.22927|0.436957|   0.1869|    82|      1518|1600|\n",
            "+-------+-------------------+------+---+----+-------+-------+----------+----------+--------+--------+--------+---------+------+----------+----+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# (3) Load the Bike Sharing dataset into a Spark DataFrame\n",
        "bike_sharing_df = sqlContext.read.format('com.databricks.spark.csv').options(header = 'true', inferschema = 'true').load('/content/day.csv')\n",
        "bike_sharing_df.show(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MNm1jZZj_fvL",
        "outputId": "d700e259-89b5-4eae-8377-7e15b1314654"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Correlation to CNT for  season 0.40610037079863526\n",
            "Correlation to CNT for  yr 0.5667097078680867\n",
            "Correlation to CNT for  mnth 0.2799771122192702\n",
            "Correlation to CNT for  holiday -0.06834771589248398\n",
            "Correlation to CNT for  weekday 0.06744341241063072\n",
            "Correlation to CNT for  workingday 0.06115606306052115\n",
            "Correlation to CNT for  weathersit -0.29739123883466345\n",
            "Correlation to CNT for  temp 0.6274940090334915\n",
            "Correlation to CNT for  atemp 0.6310656998491827\n",
            "Correlation to CNT for  hum -0.1006585621371548\n",
            "Correlation to CNT for  windspeed -0.2345449974216706\n",
            "Correlation to CNT for  cnt 1.0\n"
          ]
        }
      ],
      "source": [
        "# (4) Calculate the level of Correlation between the relevant Independent Variables and the Dependent Variable\n",
        "independent_variables = ['season', 'yr', 'mnth', 'holiday', 'weekday', 'workingday', 'weathersit', 'temp', 'atemp', 'hum', 'windspeed']\n",
        "dependent_variable = ['cnt']\n",
        "bike_sharing_df = bike_sharing_df.select( independent_variables + dependent_variable ) \n",
        "for i in bike_sharing_df.columns:\n",
        "        print( \"Correlation to CNT for \", i, bike_sharing_df.stat.corr('cnt', i))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VuBQ3E_p_fvM",
        "outputId": "5e4db991-bc90-4c89-efda-5f6b1ebc74bc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(features=DenseVector([1.0, 0.0, 1.0, 0.3442, 0.3636]), cnt=985),\n",
              " Row(features=DenseVector([1.0, 0.0, 1.0, 0.3635, 0.3537]), cnt=801),\n",
              " Row(features=DenseVector([1.0, 0.0, 1.0, 0.1964, 0.1894]), cnt=1349),\n",
              " Row(features=DenseVector([1.0, 0.0, 1.0, 0.2, 0.2121]), cnt=1562),\n",
              " Row(features=DenseVector([1.0, 0.0, 1.0, 0.227, 0.2293]), cnt=1600),\n",
              " Row(features=DenseVector([1.0, 0.0, 1.0, 0.2043, 0.2332]), cnt=1606),\n",
              " Row(features=DenseVector([1.0, 0.0, 1.0, 0.1965, 0.2088]), cnt=1510),\n",
              " Row(features=DenseVector([1.0, 0.0, 1.0, 0.165, 0.1623]), cnt=959),\n",
              " Row(features=DenseVector([1.0, 0.0, 1.0, 0.1383, 0.1162]), cnt=822),\n",
              " Row(features=DenseVector([1.0, 0.0, 1.0, 0.1508, 0.1509]), cnt=1321)]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "# (5) Generate Input Feature Vectors from the Raw Spark DataFrame\n",
        "multivariate_feature_columns = ['season', 'yr', 'mnth', 'temp', 'atemp']\n",
        "multivariate_label_column = 'cnt'\n",
        "vector_assembler = VectorAssembler(inputCols = multivariate_feature_columns, outputCol = 'features')\n",
        "bike_sharing_features_df = vector_assembler.transform(bike_sharing_df).select(['features', multivariate_label_column])\n",
        "bike_sharing_features_df.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qZh03axv_fvN",
        "outputId": "e3117f03-203c-4931-8362-1cb1f03c6b55"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(557, 174)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "# (6) Split the Raw DataFrame into a Training DataFrame and a Test DataFrame\n",
        "train_df, test_df = bike_sharing_features_df.randomSplit([0.75, 0.25], seed=12345)\n",
        "train_df.count(), test_df.count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "gCFxjwu__fvP"
      },
      "outputs": [],
      "source": [
        "# (7) Train a Multivariate Linear Regression Model on the Training DataFrame\n",
        "linear_regression = LinearRegression(featuresCol = 'features', labelCol = multivariate_label_column)\n",
        "linear_regression_model = linear_regression.fit(train_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fenuaz4n_fvQ",
        "outputId": "336cbf66-f581-4917-c768-f404373a9f23"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Coefficients: [534.0177726438907,2084.9239629668486,-55.03776131002569,1970.2427278852049,4075.8038004166997]\n",
            "Intercept: -429.568050037851\n",
            "RMSE: 1020.791883\n",
            "R-SQUARED: 0.741306\n",
            "TRAINING DATASET DESCRIPTIVE SUMMARY: \n",
            "+-------+------------------+\n",
            "|summary|               cnt|\n",
            "+-------+------------------+\n",
            "|  count|               557|\n",
            "|   mean| 4452.924596050269|\n",
            "| stddev|2008.7877956551522|\n",
            "|    min|                22|\n",
            "|    max|              8714|\n",
            "+-------+------------------+\n",
            "\n",
            "TRAINING DATASET RESIDUALS: \n",
            "+-------------------+\n",
            "|          residuals|\n",
            "+-------------------+\n",
            "|  492.8146219296144|\n",
            "|  343.5680817861023|\n",
            "|  694.0439959365583|\n",
            "| 26.531944914031783|\n",
            "|  359.4205334916021|\n",
            "| 286.70066962118153|\n",
            "| -76.81748122988392|\n",
            "| 100.06802676016605|\n",
            "| 118.21745978028912|\n",
            "|-116.32956447171364|\n",
            "| 500.57361327319313|\n",
            "| 336.18467766471053|\n",
            "| -898.0633881851779|\n",
            "| 140.72567686761067|\n",
            "| 222.20520745930662|\n",
            "|-203.19195963266293|\n",
            "|  253.9718393749538|\n",
            "|-193.50928837829565|\n",
            "| 203.45874925472208|\n",
            "| -400.2762161510834|\n",
            "+-------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# (8) Output Multivariate Linear Regression Model Summary Statistics to evaluate the Training Model\n",
        "print(\"Model Coefficients: \" + str(linear_regression_model.coefficients))\n",
        "print(\"Intercept: \" + str(linear_regression_model.intercept))\n",
        "training_summary = linear_regression_model.summary\n",
        "print(\"RMSE: %f\" % training_summary.rootMeanSquaredError)\n",
        "print(\"R-SQUARED: %f\" % training_summary.r2)\n",
        "print(\"TRAINING DATASET DESCRIPTIVE SUMMARY: \")\n",
        "train_df.describe().show()\n",
        "print(\"TRAINING DATASET RESIDUALS: \")\n",
        "training_summary.residuals.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZTJm1UW6_fvS",
        "outputId": "13d29ad0-362d-4053-f525-441749077fa4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TEST DATASET PREDICTIONS AGAINST ACTUAL LABEL: \n",
            "+------------------+----+--------------------+\n",
            "|        prediction| cnt|            features|\n",
            "+------------------+----+--------------------+\n",
            "| 976.0746662395563|1321|[1.0,0.0,1.0,0.15...|\n",
            "|  1050.01248129665| 959|[1.0,0.0,1.0,0.16...|\n",
            "| 1162.187088514198|1263|[1.0,0.0,1.0,0.16...|\n",
            "|1289.1224676804804|1510|[1.0,0.0,1.0,0.19...|\n",
            "| 1300.636622198192|1098|[1.0,0.0,1.0,0.19...|\n",
            "|1308.9999163839534|1562|[1.0,0.0,1.0,0.2,...|\n",
            "|1235.6848532836393|1746|[1.0,0.0,2.0,0.18...|\n",
            "|1384.2702586148866|1472|[1.0,0.0,2.0,0.22...|\n",
            "|1549.7784033067871|1526|[1.0,0.0,2.0,0.26...|\n",
            "| 1906.531084586451|2115|[1.0,0.0,2.0,0.31...|\n",
            "+------------------+----+--------------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# (9) Apply the Trained Multivariate Linear Regression Model to the Test DataFrame to make predictions\n",
        "test_linear_regression_predictions_df = linear_regression_model.transform(test_df)\n",
        "print(\"TEST DATASET PREDICTIONS AGAINST ACTUAL LABEL: \")\n",
        "test_linear_regression_predictions_df.select(\"prediction\", multivariate_label_column, \"features\").show(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wsafN25s_fvT",
        "outputId": "f9d76cac-f0b5-461e-af47-be0c1f37dac1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RMSE on Test Data = 964.597\n",
            "R-SQUARED on Test Data = 0.739356\n"
          ]
        }
      ],
      "source": [
        "# (10) Evaluate the performance of our Linear Regression Model on the Test DataFrame\n",
        "test_summary = linear_regression_model.evaluate(test_df)\n",
        "print(\"RMSE on Test Data = %g\" % test_summary.rootMeanSquaredError)\n",
        "print(\"R-SQUARED on Test Data = %g\" % test_summary.r2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HOdfLbHQ_fvU"
      },
      "outputs": [],
      "source": [
        "# (11) Stop the Spark Context\n",
        "spark.stop()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}